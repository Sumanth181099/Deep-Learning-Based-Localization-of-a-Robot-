
# Learning Based Localization and Control of Indoor Mobile Robots

Autonomous Systems involves three main aspects: Perception, Action/Navigation and control of the system under inspection. 
In this work, we have tackled the perception and control of an autonomous robot working in an indoor environment. This repo consists of the deep learning based robot localization implementation done using the pytorch deep learning framework. 
The data used here is a custom dataset that was generated using the ROS framework and the Gazebo simulator.  The trajectories are stored in ROS bags which can be found [here](https://drive.google.com/drive/folders/1XSOeJdBFCyY4u8PkPp0lx5N5Mg8Ivt_R?usp=sharing). The launch files required to re-implement can be found [here](https://drive.google.com/drive/folders/13o4_4M85LLr42-hGQ9q95laXKvU8fHGm?usp=sharing).
More info are provided inside the ReadMe files inside the specific folders.

You can find a more detailed explanation and the results of the work in the [report](https://drive.google.com/file/d/1hynRl29z6ciSxhXPUYXFY83fgWyJzXKo/view?usp=sharing).

![DNN](https://user-images.githubusercontent.com/65185434/120710527-df68c780-c4db-11eb-9a6a-5aa315e3c11e.JPG)
